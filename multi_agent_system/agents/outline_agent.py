"""
å¤§çº²æ™ºèƒ½ä½“æ¨¡å— - è´Ÿè´£åˆ›å»ºå†™ä½œçš„æ•´ä½“ç»“æ„å’Œå¤§çº²
"""

from langchain_core.messages import AIMessage, HumanMessage

from multi_agent_system.core.state import AgentState, copy_state
from multi_agent_system.utils.llm_utils import safe_llm_call
from multi_agent_system.utils.batch_processor import batch_processor
from multi_agent_system.config.settings import MAX_TOPIC_LENGTH, DEFAULT_TOPIC, PRIORITY_MODE

def outline_agent(state: AgentState) -> AgentState:
    """
    å¤§çº²ç­–åˆ’æ™ºèƒ½ä½“ï¼šåˆ›å»ºå†™ä½œçš„æ•´ä½“ç»“æ„å’Œå¤§çº²
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€
    """
    # åˆ›å»ºçŠ¶æ€çš„å‰¯æœ¬
    new_state = copy_state(state)
    messages = new_state["messages"]
    workspace = new_state["workspace"]
    
    # è·å–å·¥ä½œæµä¼˜åŒ–é…ç½®
    optimization = workspace.get("optimization", batch_processor.optimize_workflow(state))
    is_speed_mode = PRIORITY_MODE == "speed"
    
    # å¦‚æœå·¥ä½œç©ºé—´æ²¡æœ‰ä¸»é¢˜ï¼Œä»æ¶ˆæ¯ä¸­æå–
    if "topic" not in workspace:
        prompt = """è¯·ä»ä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯ä¸­æå–å†™ä½œä¸»é¢˜ï¼š
        
        ç”¨æˆ·æ¶ˆæ¯ï¼š
        {}
        
        è¯·åªè¿”å›ä¸€ä¸ªç®€çŸ­çš„ä¸»é¢˜ï¼ˆä¸è¶…è¿‡30ä¸ªå­—ç¬¦ï¼‰ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–é¢å¤–ä¿¡æ¯ã€‚
        ä¾‹å¦‚ï¼š'äººå·¥æ™ºèƒ½'ã€'æ•™è‚²æ”¹é©'ã€'æ°”å€™å˜åŒ–'ç­‰ã€‚
        """.format('\n'.join([msg.content for msg in messages if isinstance(msg, HumanMessage)]))
        
        print("ğŸ” æ­£åœ¨æå–ä¸»é¢˜...")
        topic_extraction = safe_llm_call(prompt)
        
        # æ¸…ç†ä¸»é¢˜æ–‡æœ¬ï¼Œä½¿å…¶é€‚åˆç”¨ä½œæ–‡ä»¶å
        extracted_topic = topic_extraction.content.strip()
        # å¦‚æœæå–çš„ä¸»é¢˜è¿‡é•¿æˆ–åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œä½¿ç”¨ä¸€ä¸ªé»˜è®¤ä¸»é¢˜
        if len(extracted_topic) > MAX_TOPIC_LENGTH or any(c in extracted_topic for c in '\\/:"*?<>|'):
            simplified_topic = "".join([c for c in extracted_topic if c.isalnum() or c in ' -_'])[:MAX_TOPIC_LENGTH].strip()
            if not simplified_topic:
                simplified_topic = DEFAULT_TOPIC
            workspace["topic"] = simplified_topic
        else:
            workspace["topic"] = extracted_topic
            
        print(f"âœ… æå–åˆ°ä¸»é¢˜: {workspace['topic']}")
    
    # åˆ›å»ºå¤§çº² - æ ¹æ®ä¼˜åŒ–æ¨¡å¼è°ƒæ•´æç¤º
    if is_speed_mode:
        outline_prompt = f"""
        ä½ æ˜¯ä¸€ä½é«˜æ•ˆçš„å¤§çº²ç­–åˆ’å¸ˆã€‚è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜åˆ›å»ºä¸€ä¸ªç®€æ´çš„å†™ä½œå¤§çº²ï¼š
        ä¸»é¢˜ï¼š{workspace.get('topic', 'é€šç”¨ä¸»é¢˜')}
        
        å¤§çº²åº”åŒ…æ‹¬ï¼š
        1. æ–‡ç« æ ‡é¢˜
        2. å¼•è¨€è¦ç‚¹
        3. 3ä¸ªä¸»è¦ç« èŠ‚ï¼ˆæ¯ä¸ªç« èŠ‚åˆ—å‡ºè¦ç‚¹ï¼‰
        4. ç»“è®ºè¦ç‚¹
        
        æ³¨æ„ï¼šè¯·ä¿æŒç®€æ´ï¼Œé™åˆ¶åœ¨500å­—ä»¥å†…ã€‚
        """
    else:
        outline_prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¤§çº²ç­–åˆ’å¸ˆã€‚è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜åˆ›å»ºä¸€ä¸ªè¯¦ç»†çš„å†™ä½œå¤§çº²ï¼š
        ä¸»é¢˜ï¼š{workspace.get('topic', 'é€šç”¨ä¸»é¢˜')}
        
        å¤§çº²åº”åŒ…æ‹¬ï¼š
        1. æ–‡ç« æ ‡é¢˜
        2. å¼•è¨€éƒ¨åˆ†
        3. 3-5ä¸ªä¸»è¦ç« èŠ‚ï¼ˆæ¯ä¸ªç« èŠ‚åŒ…å«2-3ä¸ªå­éƒ¨åˆ†ï¼‰
        4. ç»“è®ºéƒ¨åˆ†
        
        è¯·ä»¥æ¸…æ™°çš„å±‚æ¬¡ç»“æ„è¾“å‡ºå¤§çº²ã€‚
        """
    
    print("ğŸ“ æ­£åœ¨åˆ›å»ºå¤§çº²...")
    outline_response = safe_llm_call(outline_prompt)
    workspace["outline"] = outline_response.content
    workspace["optimization"] = optimization  # ä¿å­˜ä¼˜åŒ–é…ç½®ä¾›å…¶ä»–æ™ºèƒ½ä½“ä½¿ç”¨
    print("âœ… å¤§çº²åˆ›å»ºå®Œæˆ")
    
    messages.append(AIMessage(content=f"æˆ‘å·²ç»ä¸ºä¸»é¢˜ã€Œ{workspace.get('topic')}ã€åˆ›å»ºäº†å¤§çº²ï¼š\n\n{workspace['outline']}"))
    
    return new_state 