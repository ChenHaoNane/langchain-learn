{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234bfae-4010-4069-b240-be6c2c1a9db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Peng.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Peng! It's great to meet you. How can I assist you today? 😊\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Of course, Peng! I’ll remember your name for the rest of our conversation. How can I help you today? 😊\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_core.messages import ToolMessage, HumanMessage, AIMessage, BaseMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 定义 Tavily 搜索工具，最大搜索结果数设置为 2\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# 定义 BasicToolNode，用于执行工具请求\n",
    "class BasicToolNode:\n",
    "    \"\"\"一个在最后一条 AIMessage 中执行工具请求的节点。\n",
    "    \n",
    "    该节点会检查最后一条 AI 消息中的工具调用请求，并依次执行这些工具调用。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        # tools 是一个包含所有可用工具的列表，我们将其转化为字典，\n",
    "        # 通过工具名称（tool.name）来访问具体的工具\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, state: State) -> State:\n",
    "        \"\"\"执行工具调用\n",
    "        \n",
    "        参数:\n",
    "        state: 包含 \"messages\" 键的字典，\"messages\" 是对话消息的列表，\n",
    "              其中最后一条消息可能包含工具调用的请求。\n",
    "        \n",
    "        返回:\n",
    "        更新后的状态，包含所有原始消息和工具调用结果\n",
    "        \"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "        if not messages:\n",
    "            raise ValueError(\"输入中未找到消息\")\n",
    "        \n",
    "        # 获取最后一条消息（应该是AI消息，包含工具调用）\n",
    "        last_message = messages[-1]\n",
    "        \n",
    "        # 用于保存工具调用的结果\n",
    "        new_messages = list(messages)  # 复制原始消息列表\n",
    "        \n",
    "        # 遍历工具调用请求，执行工具并将结果添加到消息历史\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            # 根据工具名称找到相应的工具，并调用工具的 invoke 方法执行工具\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_args = tool_call[\"args\"]\n",
    "            tool_id = tool_call[\"id\"]\n",
    "            \n",
    "            tool_result = self.tools_by_name[tool_name].invoke(tool_args)\n",
    "            \n",
    "            # 将工具调用结果作为 ToolMessage 添加到消息历史\n",
    "            new_messages.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),  # 工具调用的结果以 JSON 格式保存\n",
    "                    name=tool_name,  # 工具的名称\n",
    "                    tool_call_id=tool_id,  # 工具调用的唯一标识符\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # 返回更新后的状态\n",
    "        return {\"messages\": new_messages}\n",
    "\n",
    "\n",
    "# 创建状态图\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 初始化 OpenAI 聊天模型\n",
    "chat_model = ChatOpenAI(model=\"deepseek-chat\")\n",
    "\n",
    "# 将工具绑定到聊天模型\n",
    "llm_with_tools = chat_model.bind_tools(tools)\n",
    "\n",
    "# 定义聊天机器人节点函数\n",
    "def chatbot(state: State) -> State:\n",
    "    \"\"\"处理消息并生成回复\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # 使用 LLM 处理消息并生成回复\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # 将 AI 回复添加到消息列表\n",
    "    new_messages = list(messages)\n",
    "    new_messages.append(response)\n",
    "    \n",
    "    return {\"messages\": new_messages}\n",
    "\n",
    "# 添加聊天机器人节点\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 创建工具节点实例并添加到图中\n",
    "tool_node = BasicToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "# 定义路由函数，检查工具调用\n",
    "def route_tools(state: State) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"\n",
    "    使用条件边来检查最后一条消息中是否有工具调用。\n",
    "    \n",
    "    参数:\n",
    "    state: 状态字典，用于存储当前对话的状态和消息。\n",
    "    \n",
    "    返回:\n",
    "    如果最后一条消息包含工具调用，返回 \"tools\" 节点，表示需要执行工具调用；\n",
    "    否则返回 \"__end__\"，表示直接结束流程。\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if not messages:\n",
    "        return \"__end__\"\n",
    "    \n",
    "    # 获取最后一条消息\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # 检查最后一条消息是否有工具调用请求\n",
    "    if (isinstance(last_message, AIMessage) and \n",
    "        hasattr(last_message, \"tool_calls\") and \n",
    "        last_message.tool_calls):\n",
    "        return \"tools\"  # 如果有工具调用请求，返回 \"tools\" 节点\n",
    "    \n",
    "    return \"__end__\"  # 否则返回 \"__end__\"，流程结束\n",
    "\n",
    "# 构建图的边\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 添加条件边，判断是否需要调用工具\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",  # 从聊天机器人节点开始\n",
    "    route_tools,  # 路由函数，决定下一个节点\n",
    "    {\n",
    "        \"tools\": \"tools\",  # 如果需要工具调用，转到工具节点\n",
    "        \"__end__\": END     # 如果不需要工具调用，结束当前流程\n",
    "    }\n",
    ")\n",
    "\n",
    "# 当工具调用完成后，返回到聊天机器人节点以继续对话\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# 创建内存检查点\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 编译图\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# 可选：生成可视化图表\n",
    "graph.get_graph().draw_mermaid_png(output_file_path=\"chatbot.png\")\n",
    "\n",
    "# 主循环\n",
    "# while True:\n",
    "#     # 获取用户输入\n",
    "#     user_input = input(\"User: \")\n",
    "    \n",
    "#     # 可以随时通过输入 \"quit\"、\"exit\" 或 \"q\" 退出聊天循环\n",
    "#     if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "#         print(\"Goodbye!\")  # 打印告别信息\n",
    "#         break  # 结束循环，退出聊天\n",
    "\n",
    "#     # 创建包含用户消息的初始状态\n",
    "#     human_message = HumanMessage(content=user_input)\n",
    "#     initial_state = {\"messages\": [human_message]}\n",
    "    \n",
    "#     # 使用 graph.stream 处理用户输入，获取聊天机器人的回复\n",
    "#     for event in graph.stream(initial_state):\n",
    "#         for value in event.values():\n",
    "#             # 获取最新消息\n",
    "#             messages = value.get(\"messages\", [])\n",
    "#             if messages and isinstance(messages[-1], AIMessage):\n",
    "#                 # 打印 AI 消息内容\n",
    "#                 print(\"Assistant:\", messages[-1].content)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# 用户输入的消息\n",
    "user_input = \"Hi there! My name is Peng.\"\n",
    "\n",
    "# 第二个参数 config 用于设置对话线程 ID\n",
    "# 在这里，\"thread_id\" 是唯一标识符，用于保存和区分对话线程。\n",
    "# 每个对话线程的状态将由 MemorySaver 保存下来，因此可以跨多轮对话继续进行。\n",
    "events = graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=user_input)]},  # 第一个参数传入用户的输入消息，消息格式为 (\"user\", \"输入内容\")\n",
    "    config,  # 第二个参数用于指定线程配置，包含线程 ID\n",
    "    stream_mode=\"values\"  # stream_mode 设置为 \"values\"，表示返回流式数据的值\n",
    ")\n",
    "\n",
    "# 遍历每个事件，并打印最后一条消息的内容\n",
    "for event in events:\n",
    "    # 通过 pretty_print 打印最后一条消息的内容\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "user_input = \"Remember my name?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=user_input)]},\n",
    "    config,\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "messages = snapshot.values['messages']\n",
    "\n",
    "\n",
    "df = pd.DataFrame([{\n",
    "    'content': msg.content,\n",
    "    'message_id': msg.id,\n",
    "    'type': type(msg).__name__,\n",
    "    'token_usage': msg.response_metadata.get('token_usage') if hasattr(msg, 'response_metadata') else None\n",
    "} for msg in messages])\n",
    "\n",
    "df.to_csv('messages.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  \\\n",
      "0                         Hi there! My name is Peng.   \n",
      "1  Hi Peng! It's great to meet you. How can I ass...   \n",
      "2                                  Remember my name?   \n",
      "3  Of course, Peng! I’ll remember your name for t...   \n",
      "\n",
      "                                    message_id          type  \\\n",
      "0         1c4b9d11-6aad-4a94-85b2-0dc545d82754  HumanMessage   \n",
      "1  run--b7b862ad-cb12-4aa0-bb9b-d78098873f47-0     AIMessage   \n",
      "2         dcd9dbcc-4318-4c7d-a248-470ae7e7c61c  HumanMessage   \n",
      "3  run--a9bd3fe2-b209-49b5-9954-558807f4c660-0     AIMessage   \n",
      "\n",
      "                                         token_usage  \n",
      "0                                               None  \n",
      "1  {'completion_tokens': 19, 'prompt_tokens': 152...  \n",
      "2                                               None  \n",
      "3  {'completion_tokens': 27, 'prompt_tokens': 178...  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
